Metadata-Version: 2.4
Name: ais-kadaster-mcp
Version: 0.1.0
Summary: Kadaster query catalog + SPARQL execution extractor script
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: requests>=2.32.0

# ais-kadaster-mcp

Small Python repo containing `scripts/kadaster.py`, which crawls the Kadaster Labs query catalog, fetches query details, optionally executes the SPARQL, and writes JSON examples to disk.

## Prereqs

- Python (recommended: `3.11+`, see `.python-version`)
- `uv` installed: https://docs.astral.sh/uv/

## Setup

Create a local virtualenv and install dependencies:

```bash
uv sync
```

Optional: copy `.env.example` to `.env` and run with:

```bash
uv run --env-file .env kadaster-extract
```

To build compacted bundles used by the notebooks:

```bash
python3 scripts/collect_non_empty.py
python3 scripts/collect_rdf.py
```

## Run

Run the script directly:

```bash
uv run python scripts/kadaster.py
```

Or run via the installed console script:

```bash
uv run kadaster-extract
```

Output is written to `data/kadaster_dataset/` (gitignored).

## Configuration

Defaults live at the top of `scripts/kadaster.py` (e.g. `OUTPUT_DIR`, `DELAY_BETWEEN_REQUESTS`, `SPARQL_ENDPOINT`).

You can override defaults with env vars:

```bash
KADASTER_OUTPUT_DIR=data/kadaster_dataset \
KADASTER_BASE_API_URL=https://data.labs.kadaster.nl/_api \
KADASTER_SPARQL_ENDPOINT=https://data.labs.kadaster.nl/_api/datasets/kadaster/kkg/services/kkg/sparql \
KADASTER_SPARQL_REFERRER=https://data.labs.kadaster.nl/kadaster/kkg/sparql \
KADASTER_DELAY_BETWEEN_REQUESTS=0.1 \
KADASTER_TIMEOUT_SECONDS=10 \
KADASTER_MAX_WORKERS=3 \
uv run kadaster-extract
```

If the SPARQL endpoint requires an authenticated browser session, you can also pass cookies:

```bash
KADASTER_COOKIE="key=value; other=thing" uv run kadaster-extract
```

Execution uses `KADASTER_TIMEOUT_SECONDS` (default `10`) and `KADASTER_MAX_WORKERS` (default `3`).

## Dev (optional)

Lint:

```bash
uv run ruff check .
```

## Notebook

The repo includes an analysis notebook at `notebooks/kadaster_insights.ipynb`.

```bash
uv sync
uv run python -m ipykernel install --user --name ais-kadaster-mcp --display-name "ais-kadaster-mcp"
uv run python -m notebook
```

There is also a few-shot selection notebook at `notebooks/fewshot_judge.ipynb` that can use an OpenAI-key-backed LLM judge to score candidates and export `data/fewshot_topk.json`.

## Dataset Findings

From the current scrape (365 queries), `execution_result_sample` outcomes are roughly:

- `non_empty` (SELECT with results): 41
- `empty` (SELECT with no bindings): 249
- `error` (timeouts/HTTP errors): 46
- `rdf` (Turtle graph results, e.g. CONSTRUCT/DESCRIBE): 24
- `boolean` (ASK): 1
- `unknown`: 4

## Notes

See `POC.md` for the current proof-of-concept approach.

This work is intended to become an MCP-backed workflow that can be invoked from an agent client such as `gemini-cli`.
